{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "- Various forms of corruption in images are investigated\n",
    "- A U-Net type architecture is employed where the input and target have been independently corrupted using the same type of corruption\n",
    "- It seems that during training inputs and targets are with randomly chosen parameters each time they are fed to the model whilst during validation so that it is different each time whilst at validation the corruption random is with fixed parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random pixel noise and $L_2$ loss\n",
    "- **Gaussian noise**\n",
    "    - White Gaussian noise corruptipn is where each pixel $x_i$ in image is replaced with $\\hat{x}_i = x + \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "    - Brown Gaussian noise corruption is where interpixel correlation is introduced by blurring the white Gaussian noise image using a spatial Gaussian filter\n",
    "- **Poisson noise** is where $x_i$ is replaced by a pixel drawn from a Poisson distribution with mean $x_i'$\n",
    "- **Bernouilli noise** is where $x_i$ is deleted at random according to a Bernouilli distribution with probability $p$ and for this noise gradients are not backpropagated into the missing pixels\n",
    "- On average across different datasets, noise2noise yields results comparable to training with clean targets (31.63 dB/31.61 dB clean/noisy  for Gaussian, 30.59 dB/30.57 dB for Poisson and 31.85 dB/32.02 dB for Bernouilli) \n",
    "- For all these methods the $L_2$ loss works because the expected value of the noisy image will be the original image:\n",
    "    - This is the case for Bernouilli noise as well because of how the gradients are masked for missing pixel.\n",
    "    - The network \"sees\" each pixel in a fraction $p$ of the $N$ times approximately it sees the image.\n",
    "    - The average is therefore across $pN$ pixels rather $N$ pixels and each time the pixel has the same value so the average is the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text removal and $L_1$ loss\n",
    "- Text of different colours and font styles is overlaid on top of the image.\n",
    "- With any reasonable quantity of overlaid text a pixel will retain its original value more often than not across iterations \n",
    "\n",
    "$$p(\\hat{x}_i = x_i) \\geq p(\\hat{x}_i \\neq x_i) \\implies p(\\hat{x}_i = x_i) + p(\\hat{x}_i = x_i) \\geq p(\\hat{x}_i = x_i) + p(\\hat{x}_i \\neq x_i) = 1 \\implies p(\\hat{x}_i = x_i) \\geq \\frac{1}{2}$$\n",
    "      \n",
    "- The median of a distribution $m$ is defined as the value which satisfies\n",
    "\n",
    "    $$p(x \\geq m) \\geq \\frac{1}{2} \\\\\n",
    "      p(x \\leq m) \\geq \\frac{1}{2} $$\n",
    "      \n",
    "- Thus $x_i$, the original pixel value, is the median of $\\hat{x}_i$ since the following inequalities hold\n",
    "    $$p(\\hat{x}_i \\geq x_i)  = p(\\hat{x}_i \\gt x_i) + p(\\hat{x}_i = x_i) \\geq \\frac{1}{2}\\\\ \n",
    "    p(\\hat{x}_i \\leq x_i)  = p(\\hat{x}_i \\lt x_i) + p(\\hat{x}_i = x_i) \\geq \\frac{1}{2}$$\n",
    "- So for this type of corruption the $L_1$ loss works better than the $L_2$ loss as the latter leads to an averaging over the original pixel value and the unrelated text colours.\n",
    "- The performance using $L_1$ is 35.75 dB which is close to 35.82 dB with clean targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random-valued impulse noise and $L_0$ loss\n",
    "\n",
    "- The image with pixel values normalised to such that $x_i \\in [0,1]$ is perturbed according to the following distribution:\n",
    "\n",
    "    $$p(\\hat{x}_i) = \\left\\{\\begin{array}{ll}\n",
    "                   1-p \\text{, }\\text{  }\\hat{x}_i  = x_i \\\\\n",
    "                   p \\text{, }\\text{  }\\hat{x}_i \\in [0,x_i) \\cup (x_i,1] \\\n",
    "                \\end{array}\n",
    "              \\right.$$\n",
    "- Actually for each pixel in an RGB image we need three values but they will be independently sampled so we can analyse each pixel in each channel separately\n",
    "- To see that this is a distribution\n",
    "\n",
    "$$\\int_0^1 p(\\hat{x}_i)\\cdot d\\hat{x}_i = \\int_0^{x_i} p \\cdot d\\hat{x}_i+ (1 - p) + \\int_{x_i}^1 p\\cdot d\\hat{x}_i = px_i  + (1 - p) + p(1 - x_i) = 1 - p + p = 1$$\n",
    "\n",
    "- $x_i$ is the mode of this distribution\n",
    "- To see this intuitively note that  $p(\\hat{x}_i = x_i) = 1-p$ but for any other $x_j \\neq x_i$ the probability of the small region between $x_j - \\frac{\\Delta}{2}$ and $x_j + \\frac{\\Delta}{2}$ will be $p\\Delta \\ll 1 - p$\n",
    "- For this example therefore the $L_0$ loss, since it is minimised by the mode, works better than $L_1$ or $L_2$.\n",
    "- Performance with $L_0$ is 28.43 dB which is comparable to 28.86 dB using clean targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo rendered images\n",
    "- Monte Carlo path tracing is used to generate physically accurate rendering of virtual environments.\n",
    "- It involves drawing random sequences of scattering events (or light paths) that connect light sources and virtual sensors in the sense, and the radiance carried by them is integrated across all paths.\n",
    "- Noise is difficult to get rid off as distribution can be complex for various reasons:\n",
    "    - Varies from pixel to pixel\n",
    "    - Depends a lot on scene configuration and rendering parameters\n",
    "    - Possibly arbitrarily multi-modal\n",
    "    - Sometimes extremely long-tailed with rare outliers\n",
    "- Pixel luminances can vary significantly so they are compressed to a fixed range using a non-linear function.\n",
    "- Non-linearity of this function makes MSE loss unsuitable so a different loss function more appropriate for high dynamic range images is used\n",
    "    $$ \\text{L}_\\text{HDR} = \\frac{\\left(f_\\theta\\left(\\hat{x}\\right) âˆ’ \\hat{y}\\right)^2}{\\left(f_\\theta\\left(\\hat{x}\\right) + 0.01\\right)^2}$$\n",
    "- Using a fixed set of images, it takes about twice as long using noisy images to get similar performance as using clean ones (31.83 dB).\n",
    "- However it is much faster to render noisy images so there seems to be a quality/speed tradeoff.\n",
    "- In an online setting using noisy targets yielded improvements almost as good as clean ones (values are not given but from the plot in Figure 8 looks both seem to be around 30dB with clean marginally higher) but significantly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MRI \n",
    "- MRI produces 3D images essentially by sampling the Fourier transform of the signal\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
