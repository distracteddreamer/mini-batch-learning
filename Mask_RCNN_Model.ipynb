{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - sample_select for rpn\n",
    "# - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stop_gradient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will set out all steps involved in building a Faster RCNN model, assuming we have access to the necessary functions. Then we will write each of the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "#### BACKBONE ####\n",
    "##################\n",
    "# Run the backbone\n",
    "x = backbone(images)\n",
    "\n",
    "\n",
    "#################################\n",
    "#### REGION PROPOSAL NETWORK ####\n",
    "#################################\n",
    "# - Generate labels for anchor boxes, also return normalized anchors\n",
    "bboxes, labels, anchors = generate_anchor_targets(bboxes_gt)\n",
    "\n",
    "# Run RPN to obtain proposals and logits\n",
    "proposals, logits = rpn(x, config)\n",
    "\n",
    "# Make an array of image indicies as subsequent select steps will cause batch dimension to be lost\n",
    "image_inds = tf.tile(tf.range(tf.shape(logits)[0])[:,None], [1, tf.shape(logits)[1]]) # batch_size x n_rois\n",
    "\n",
    "# We pad the bounding boxes to have an equal number per image per batch.\n",
    "# An anchor box that does not have 0.7 IoU or maximum IoU that is greater than 0 with \n",
    "# non-padded ground truth box, may therefore assigned a padded box as target\n",
    "# (since all anchor boxes will have IoU zero with this so all will have max IoU)\n",
    "# So we need to filter these\n",
    "# Select only non-padded\n",
    "bboxes, proposals, logits, labels, image_inds = select_items([bboxes, proposals, logits, labels, image_inds], \n",
    "                                                             get_unpadded(bboxes))\n",
    "\n",
    "\n",
    "bboxes_spl, proposals_spl, logits_spl, labels_spl, image_inds_spl \\ \n",
    "                                = select_pos_neg_samples([bboxes, proposals, logits, labels, image_inds], \n",
    "                                                        tf.equal(labels, 1), tf.equal(labels, -1), \n",
    "                                                        config.rpn_n_pos, config.rpn_n_neg)\n",
    "\n",
    "# Clf losses using pos/neg items\n",
    "is_pos = tf.equal(labels_spl, 1)\n",
    "clf_loss = tf.losses.sigmoid_cross_entropy_with_logits(logits=logits_spl[...,0], \n",
    "                                                       labels=tf.to_float(is_pos))\n",
    "\n",
    "# Reg losses using pos items (the function will only find the loss for the positive proposals)\n",
    "reg_loss = tf.losses.huber_loss(*select_items([proposals_spl, bboxes_spl], is_pos))\n",
    "\n",
    "# Combine losses\n",
    "loss_rpn = clf_loss/config.n_clf + config.rpn_lmd*reg_loss/config.n_reg\n",
    "\n",
    "\n",
    "##################################\n",
    "#### DETECTOR - PREPROCESSING ####\n",
    "##################################\n",
    "\n",
    "# - Select pos/neg of: proposals, logits, anchors, image_inds\n",
    "proposals, logits, anchors, image_inds = select_items([proposals, logits, anchors, image_inds], \n",
    "                                                      tf.not_equal(labels, 0))\n",
    "\n",
    "# - Recover bounding boxes - this will be normalized as anchors are normalized\n",
    "proposals = recover_boxes(proposals, anchors)\n",
    "\n",
    "# For cross-boundary proposals, either trim to image boundaries\n",
    "# or discard, and discard any which are not valid bounding boxes i.e. x2 <= x1, etc.\n",
    "proposals = tf.clip_by_value(proposals, 0, 1)\n",
    "proposals_valid = tf.any(tf.greater_equal(proposals[...,:2], proposals[...,2:]), axis=-1)\n",
    "proposals, logits, image_inds = select_items([proposals, logits, image_inds], proposals_valid)\n",
    "\n",
    "# - Normalize bboxes\n",
    "bboxes_normed = norm_bboxes(bboxes_gt)\n",
    "\n",
    "# Process items for each image\n",
    "proposals, bboxes, labels, image_inds = tf.map_fn(elems = tf.unique(image_inds)[0], fn = process_items)\n",
    "\n",
    "# # Concatenate proposals, bboxes, labels, targets, image_inds\n",
    "# items = [tf.reshape(item, [-1, tf.shape(item)[-1]]) for item in items]\n",
    "\n",
    "\n",
    "############################\n",
    "#### DETECTOR - NETWORK ####\n",
    "############################\n",
    "#Stop gradients for the proposals so that they are regarded as constant for the purposes\n",
    "#of training the detector\n",
    "proposals = tf.stop_gradients(proposals)\n",
    "bboxes_det = transform_bboxes(bboxes_normed, proposals)\n",
    "\n",
    "# Crop bboxes\n",
    "roi_pool = tf.image.crop_and_resize(image=x, boxes=proposals, box_ind=image_inds, \n",
    "                                    crop_size=config.roi_pool_size)\n",
    "\n",
    "# Get logits and pred_bboxes\n",
    "rois, class_logits = detector(roi_pool)\n",
    "\n",
    "# Clf losses using pos/neg items \n",
    "clf_loss_det = tf.losses.sparse_softmax_cross_entropy(logits=class_logits, labels=class_labels)\n",
    "\n",
    "# Reg losses using pos items (the function will only find the loss for the positive boxes)\n",
    "class_rois = tf.gather(rois, class_labels, axis=-1)\n",
    "is_pos = tf.greater(class_labels, 0)\n",
    "reg_loss_det = tf.losses.huber_loss(*select_items([class_rois, bboxes_det], is_pos))\n",
    "loss_det = clf_loss_det + config.det_lmd*reg_loss_det\n",
    "\n",
    "#################\n",
    "#### METRICS ####\n",
    "#################\n",
    "# Total loss\n",
    "total_loss = loss_det + loss_rpn\n",
    "\n",
    "# Recover predicted bounding boxes - these will also be normalized \n",
    "rois = recover_boxes(rois, proposals)\n",
    "\n",
    "# Optionally apply nms per class\n",
    "rois, bboxes, logits, labels, image_inds \\\n",
    "    = process_preds(rois, bboxes, logits, labels, image_inds, n_classes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_bboxes(bboxes, config):\n",
    "    return bboxes/tf.stack([config.height, config.width]*2)\n",
    "\n",
    "def get_centres_dims(bboxes):\n",
    "    # Transforms [x1, y1, x2, y2] to [x_c, y_c, h, w]\n",
    "    centres = (bboxes[...,2:] + bboxes[...,:2])/2 # (..., (x_c, y_c))\n",
    "    dims = bboxes[...,2:] - bboxes[...,:2] + 1 # (..., (h, w))\n",
    "    return centres, dims\n",
    "\n",
    "def transform_bboxes(bbox1, bbox2):\n",
    "    centres1, dims1 = get_centres_dims(bbox1)  # a_i0 x a_i1 x a_i2 x ... x 4\n",
    "    centres2, dims2 = get_centres_dims(bbox2) # b_i0 x b_i1 x b_i2 x ... x 4\n",
    "    \n",
    "    # d_in = a_in = b_in or d_in = max(a_in, b_in) if a_in != b_in and a_in = 1 or b_in = 1\n",
    "    centres_trans = (centres1 - centres2)/dims2  # d_i0 x d_i1 x d_i2 x ... x ... x 2\n",
    "    dims_trans  =  tf.log(dims1/dims2)  # d_i0 x d_i1 x d_i2 x ... x ... x 2\n",
    "    \n",
    "    targets = tf.concat([centres_trans, dims_trans], axis=-1) # d_i0 x d_i1 x d_i2 x ... x ... x 4\n",
    "    return targets\n",
    "    \n",
    "def get_transformed_bboxes(bboxes, config):\n",
    "    # bboxes: # batch_size x n_anchors x 4\n",
    "    anchors = tf.constant(config.anchors, tf.float32)[None] # 1 x n_anchors x 4 (xa_1, ya_1, xa_2, ya_2)\n",
    "    bboxes = tf.to_float(bboxes)\n",
    "\n",
    "    anchors = norm_bboxes(anchors)\n",
    "    bboxes = norm_bboxes(bboxes)\n",
    "    \n",
    "    bboxes = transform_bboxes(bboxes, anchors) # batch_size x n_anchors x 4\n",
    "    not_padding = tf.to_float(tf.reduce_any(tf.greater(anchor_targets, 0), axis=-1, keepdims=True)) # batch_size x n_anchors x 1\n",
    "    \n",
    "    return not_padding*bboxes, not_padding*anchors # batch_size x n_anchors x 4\n",
    "\n",
    "def generate_anchor_targets(bboxes, config):\n",
    "    # bboxes: batch_size x max_n_bboxes x 4\n",
    "    ious = find_iou(config.anchors.astype(np.int32), bboxes) #batch_size x n_anchors x max_n_bboxes\n",
    "    pos_mask, target_inds = identify_pos_boxes(ious, config.rpn_pos_th) #(batch_size x n_anchors, batch_size x n_anchors)\n",
    "    neg_mask = identify_neg_rois(ious, pos_mask, config.rpn_neg_th) #batch_size x n_anchors\n",
    "\n",
    "    anchor_labels = tf.zeros(tf.shape(pos_mask)) #batch_size x n_anchors\n",
    "    anchor_labels = tf.where(pos_mask, tf.ones_like(anchor_labels), anchor_labels) #batch_size x n_anchors\n",
    "    anchor_labels = tf.where(neg_mask, -tf.ones_like(anchor_labels), anchor_labels) #batch_size x n_anchors\n",
    "    anchor_bboxes = tf.batch_gather(bboxes, tf.to_int32(target_inds)) #batch_size x n_anchors x 4\n",
    "    anchor_bboxes = get_transformed_bboxes(bboxes)\n",
    "    return anchor_bboxes, anchor_labels, anchors #(batch_size x n_anchors, batch_size x n_anchors x 4, batch_size x n_anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn(x, config):\n",
    "    n_anchors = self.config.n_anchors\n",
    "    conv = tf.layers.conv2d(inputs=x, activation=tf.nn.relu, **config.tiny_conv_kwargs)\n",
    "    #TODO: add bn, relu as needed\n",
    "    clf = tf.layers.conv2d(inputs=conv, kernel_size=1, filters=1*n_anchors, padding='same')\n",
    "    reg = tf.layers.conv2d(inputs=conv, kernel_size=1, filters=4*n_anchors, padding='same')\n",
    "    clf = tf.reshape(clf, tf.concat([tf.shape(clf)[:1], [-1, 1]], axis=0))\n",
    "    reg = tf.reshape(reg, tf.concat([tf.shape(reg)[:1], [-1, 4]], axis=0))\n",
    "    return clf, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_items(arrs, mask):\n",
    "    arrs =[tf.boolean_mask(arr, mask) for arr in arrs]\n",
    "    return arrs\n",
    "\n",
    "def gather_items(arrs, inds):\n",
    "    arrs = [tf.gather(arr, inds) for arr in arrs]\n",
    "    return arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_loss(logits, anchor_labels):\n",
    "    losses = tf.losses.sigmoid_cross_entropy_with_logits(logits=pos_neg_logits[...,0], \n",
    "                                                     labels=anchor_labels)\n",
    "    return losses\n",
    "\n",
    "def reg_loss(proposals, targets):\n",
    "    losses = tf.losses.huber_loss(proposals, targets)\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(centres, dims):\n",
    "    shift = (dims - 1)/2\n",
    "    corner1 = centres - shift\n",
    "    corner2 = centres + shift\n",
    "    return tf.concat([corner1, corner2], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_boxes(boxes1, boxes2):\n",
    "    #proposals: batch_size x n_anchors\n",
    "    #anchors: batch_size x n_anchors\n",
    "    \n",
    "    centres2 = boxes2[...,:2]\n",
    "    dims2 = boxes2[...,2:]\n",
    "    \n",
    "    centres1 =  centres2 + boxes1[...,:2]*dims2\n",
    "    dims1 = tf.exp(boxes1[...,:2])*dims2\n",
    "    \n",
    "    rois = get_corners(centres1, dims1)\n",
    "    return rois\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unpadded(bboxes):\n",
    "    return tf.reduce_any(tf.greater(bboxes, 0), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_items(image_ind):\n",
    "    # - Select items corresponding to image\n",
    "    proposals_img, logits_img = select_items([proposals, logits], \n",
    "                                                 tf.equal(image_inds, image_ind))\n",
    "    \n",
    "    # Select classes and bboxes \n",
    "    classes_img = classes[image_ind]\n",
    "    bboxes_img = bboxes_normed[image_ind]\n",
    "\n",
    "    # Select unpadded only\n",
    "    classes_img, bboxes_img = select_items([classes_img, bboxes_img],\n",
    "                                           get_unpadded(bboxes_img))\n",
    "    \n",
    "    # - Select nms of: proposals, targets (logits used for scoring)\n",
    "    proposals_img = get_nms(proposals_img, logits_img)\n",
    "    \n",
    "    # - Generate labels for the proposals, sampling positives and negatives\n",
    "    proposals_img, bboxes_img, classes_img = generate_det_inputs(proposals_img, bboxes_img, classes_img)\n",
    "    \n",
    "#     # - Select pos/neg of: proposals, bboxes, labels, image_inds, sample from these\n",
    "#     proposals_pos, bboxes_pos, labels_pos = sample_select([proposals_pos, bboxes_pos, labels_pos], \n",
    "#                                                           tf.greater(labels_img, 0))\n",
    "    \n",
    "#     # - Select neg of: proposals, class_labels, sample from these\n",
    "#     # - Here bboxes are just zeros (returned for convenience)\n",
    "#     proposals_neg, bboxes_neg, labels_neg = sample_select([proposals_pos, bboxes_pos, labels_pos], \n",
    "#                                                           tf.equal(labels_img, 0))\n",
    "    \n",
    "    # Concatenate pos and neg\n",
    "#     proposals_img = tf.concat([proposals_pos, proposals_neg], axis=0)\n",
    "#     bboxes_img = tf.concat([bboxes_pos, bboxes_neg], axis=0)\n",
    "#     labels_img = tf.concat([labels_pos, labels_neg], axis=0)\n",
    "    img_inds = tf.tile([image_ind], [tf.shape(labels_img)])\n",
    "    \n",
    "    return proposals_img, bboxes_img, labels_img, img_inds\n",
    "\n",
    "def process_preds(rois, bboxes, logits, labels, image_inds, n_classes, config):\n",
    "    \n",
    "    def _nms_fn(n):\n",
    "        image_ind = n[0]\n",
    "        class_label = n[1]\n",
    "        rois, logits = select_items([rois, logits], tf.logical_and(tf.equal(labels, image_ind), \n",
    "                                                                   tf.equal(labels, class_label)))\n",
    "        inds = tf.image.non_max_suppression(rois, tf.nn.sigmoid(logits),\n",
    "                                           max_output_size=config.max_rois,\n",
    "                                           iou_threshold=config.roi_nms_th)\n",
    "        rois, bboxes, logits = gather_items([rois, bboxes, logits], inds)\n",
    "        n_rois = tf.shape(rois)[0]\n",
    "        return rois, bboxes, logits, tf.tile([class_label], n_rois), tf.tile([image_ind], n_rois)\n",
    "    \n",
    "    rois, bboxes, logits, class_labels, image_inds \\\n",
    "                = tf.map_fn(elems=tf.meshgrid(image_inds, n_classes), fn=_nms_fn)\n",
    "    return rois, bboxes, logits, class_labels, image_inds\n",
    "        \n",
    "\n",
    "def get_nms(proposals, logits):\n",
    "    nms_inds = tf.image.non_max_suppression(proposals, tf.nn.sigmoid(logits),\n",
    "                                           max_output_size=config.max_output_size,\n",
    "                                           iou_threshold=config.proposal_nms_th)\n",
    "    proposals = tf.gather(proposals, nms_inds)\n",
    "    return proposals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pos_neg_samples(items, is_pos, is_neg, n_pos, n_neg):\n",
    "    # - Select pos of: logits, labels, sample from these\n",
    "    pos_keep = tf.random.shuffle(tf.where(is_pos))[:n_pos]\n",
    "    neg_keep = tf.random.shuffle(tf.where(is_neg))[:n_neg + n_pos - tf.shape(pos_keep)[0]]\n",
    "    \n",
    "    bboxes, proposals, logits, labels = gather_items(items, tf.concat([pos_keep, neg_keep], axis=0))\n",
    "    \n",
    "    return bboxes, proposals, logits, labels \n",
    "\n",
    "# def select_rpn_samples(bboxes, proposals, logits, labels, image_inds)\n",
    "#     # - Select pos of: logits, labels, sample from these\n",
    "#     pos_keep = tf.random.shuffle(tf.where(tf.equal(labels, 1)))[:config.rpn_n_pos]\n",
    "#     neg_keep = tf.random.shuffle(tf.where(tf.equal(labels, -1)))[:2*config.rpn_n_pos - tf.shape(pos_keep)[0]]\n",
    "    \n",
    "    \n",
    "#     bboxes, proposals, logits, labels = gather_items([bboxes, proposals, logits, labels],\n",
    "#                                                      tf.concat([pos_keep, neg_keep], axis=0))\n",
    "    \n",
    "#     return bboxes, proposals, logits, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_det_inputs(proposals, bboxes, class_labels, config):\n",
    "    #proposals: n_rois\n",
    "    #bboxes: n_bboxes\n",
    "    \n",
    "    ious = find_iou(proposals[..., None], bboxes[...,None,:]) # n_rois x n_bboxes\n",
    "    \n",
    "    # Get labels - note that is_pos and is_neg are disjoint \n",
    "    is_pos = tf.any(tf.greater_equal(ious, config.det_pos_th), axis=-1) # n_rois\n",
    "    is_neg = tf.any(tf.logical_and(tf.greater_equal(ious, config.det_neg_th_ge), \n",
    "                            tf.less(ious, config.det_neg_th_lt)), axis=-1) # n_rois\n",
    "    \n",
    "    \n",
    "    # Find bboxes with top IoU to match targets\n",
    "    inds_match = tf.argmax(ious, axis=-1) # n_rois\n",
    "    \n",
    "    \n",
    "    #Can be lazy with gathering bboxes for all because they won't be used for non-positives\n",
    "    #But need to be careful that non-positive class_labels are zero - still a bit lazy as\n",
    "    #neutral will also be zero but these get filtered below\n",
    "    bboxes = tf.gather(bboxes, inds_match) # n_rois x 4\n",
    "    class_labels = tf.where(is_pos, tf.gather(class_labels, inds_match), \n",
    "                            tf.zeros_like(class_labels)) # n_rois \n",
    "    \n",
    "    # Get samples\n",
    "#     pos_keep = tf.random.shuffle(tf.where(is_pos))[:config.det_n_pos] # n_pos\n",
    "#     neg_keep = tf.random.shuffle(tf.where(is_neg))[:2*config.det_n_pos - tf.shape(pos_keep)[0]] # n_pos\n",
    "    \n",
    "#     proposals, bboxes, class_labels = gather_items([proposals, bboxes, class_labels],\n",
    "#                                     tf.concat([pos_keep, neg_keep], axis=0)) # n_rois x 4, n_rois x 4, n_rois\n",
    "    \n",
    "    proposals, bboxes, class_labels = select_pos_neg_samples([proposals, bboxes, class_labels], \n",
    "                                                             is_pos, is_neg, config.det_n_pos, config.det_n_neg)\n",
    "    \n",
    "    return proposals, bboxes, class_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
