{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Estimators - a very quick guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we will not implement a model or input pipeline assuming that we have already written functions that take care of these matters. First we need a model function that builds the model graph and returns different outputs based on whether we are training, validating or testing the model. This should have the following signature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments `features` and `labels` contains the inputs and ground truth. You can pass in multiple inputs or labels using iterables. We will discuss below `mode` which refers to whether training, validating or testing the model. You can use the optional argument `params` to configure your model.\n",
    "\n",
    "We need to build the model graph and obtain the loss within before returning different outputs based on `mode`. Let us say another function `get_model` builds the model graph. Then the first step would be call this function within `model_fn`. Notice how we have made use of `params` to pass in additional arguments to be used internally within `model_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logits = get_model(features, **params['model_kwargs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that we have softmax classification output, let us also get the predicted probabilities and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    probs_pred = tf.nn.softmax(logits)\n",
    "    labels_pred = tf.argmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add a cross entropy loss op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally (assuming our classes are balanced) let us add an op to find the accuracy of our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `mode` can be `TRAIN`, `EVAL` or `PREDICT` or and`model_fn` needs to handle each of these. These corresponding to training, validation and testing. For each mode you return an instance of `tf.EstimatorSpec`. For each mode `tf.EstimatorSpec` has different required arguments:\n",
    "\n",
    "- For `TRAIN` you need to pass in a `train_op` and a `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate==0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `EVAL` you need to pass in a `loss`. In the example below we also pass in `eval_metric_ops` which should be a `dict`. Any metrics you pass in this manner will be displayed on TensorBoard along with the `loss`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if mode == tf.estimator.ModeKey.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                loss=loss, eval_metric_ops={'accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `PREDICT` you need to pass in `predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                          predictions=labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build an classifier using `tf.Estimator`. Assume that `model_kwargs` is a `dict` that we have defined elsewhere whilst `model_dir` is the location at which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = './'\n",
    "    params = {\n",
    "        \"model_kwargs\": model_kwargs\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the model, we also need to pass in the `input_fn` parameter for each mode. This function should output the a tuple (`features`, `labels`) pair containing a mini-batch of inputs and labels required by `model_fn`. For example (again assuming we have a `'train_input_fn`, `valid_input_fn` and `test_input_fn` already). Note that we can specify the number of `steps` for which to train but this is not necessary if code within `train_input_fn` generates a `tf.errors.OutOfRange error` (as might be the case use `tf.data.Dataset`) or `StopIteration` exception as this will be the signal to stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(input_fn=train_input_fn)\n",
    "#classifier.train(input_fn=train_input_fn, steps=10000)\n",
    "\n",
    "classifier.eval(input_fn=valid_input_fn)\n",
    "\n",
    "classifier.predict(input_fn=test_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
