{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-convolutional U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_conv_2d(inputs, **conv_kwargs):\n",
    "    with tf.variable_scope('semi_conv_2d'):\n",
    "        inputs = tf.layers.conv2d(inputs, kernel_size=1, **conv_kwargs)\n",
    "        shape = tf.shape(inputs)\n",
    "        inds = [tf.arange(shape[i]) for i in tf.range(shape)]\n",
    "        delta = tf.meshgrid(*inds)/shape\n",
    "        inputs = inputs + delta\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype=tf.int32, shape=[])\n",
    "b = tf.one_hot([[1,9,1,0]], depth=a, axis=0)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(b, {a:5}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.random((7,4,5,6)) > 0.5\n",
    "b = np.random.random((9,4,5,6))\n",
    "(a[np.newaxis]*b[:,np.newaxis]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "- The loss is defined for the set of instances $\\mathcal{S}$ within an image but could also be extended to the set of instances within a mini-batch \n",
    "\n",
    "    $$\\mathcal{L}(\\Psi|\\mathbf{x}, \\mathcal{S}) = \n",
    "    \\sum_{S \\in \\mathcal{S}} \\frac{1}{\\lvert S \\rvert} \n",
    "    \\sum_{u \\in S}\\left\\lVert\\Psi_u(\\mathbf{x}) - \\frac{1}{\\lvert S \\rvert}\\sum_{u \\in S}\\Psi_u(\\mathbf{x})\\right\\rVert$$\n",
    "    \n",
    "- Specifically for each instance $S$, the loss is the mean of the Euclidean distances between the embeddings for each pixel $u \\in S$ and the mean embedding over all the pixels in that instance.   \n",
    "- Notice that it only encourages embeddings within each instance to be similar and does not explicitly discourage embeddings in different instances to be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the loss for a mini-batch\n",
    "- Now we will implement the loss for a mini-batch with an arbitrary maximum number of instances in any image in the batch\n",
    "- The instances in an image $\\mathbf{x}$ are labelled $0,...,|\\mathcal{S}|-1$ for $\\mathcal{S}$ instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_conv_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Implements equation 5 from https://arxiv.org/abs/1807.10712 for a mini-batch of images.\n",
    "    \n",
    "    Args:\n",
    "        y_true (Tensor): sparse label tensor of shape batch_size x height x width, \n",
    "                         with a separate number for each instance present in the image.\n",
    "                         Requires that the values are consecutive integers starting from 0.\n",
    "        y_pred (Tensor): sparse prediction tensor of shape batch_size x height x width x channels\n",
    "        \n",
    "    Returns:\n",
    "        semi-convolutional loss \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In simple multi-class segmentation where we don't keep instances of the same class separate we can group together \n",
    "- But here it is important to keep the instances separate across batches since instance $i$ in one image is not necessarily from the same class as instance $i$ from another image. \n",
    "- We obtain a one-hot encoded label map where the depth is the maximum number of instances in any of the images in the batch.\n",
    "- Then for each instance we use the one-hot map to mask all the embeddings which don't belong pixels in that instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #find the maximum number of instances in any image in this batch\n",
    "    n_inst_max = tf.max(y_true) \n",
    "    \n",
    "    #batch_size x height x width -> n_inst_max x batch_size x height x width\n",
    "    y_true_one_hot = tf.one_hot(y_true, depth=n_inst_max, axis=0)\n",
    "    \n",
    "    #results in tensor of shape batch_size x n_inst_max x height x width x channels\n",
    "    y_pred_dense = y_true_one_hot[tf.newaxis]*y_pred[:,tf.newaxis]\n",
    "    \n",
    "    #reshape to (batch_size*n_inst_max) x height x width x channels\n",
    "    y_pred_dense = tf.reshape(y_pred_dense, \n",
    "                              tf.concat([[-1], tf.shape(y_pred_dense)[2:]], axis=0))\n",
    "    \n",
    "    #batch_size x n_inst_max x height x width x channels -> (batch_size*n_inst_max) x height x width\n",
    "    y_true_one_hot = tf.reshape(y_true_one_hot,\n",
    "                                tf.concat([[-1], tf.shape(y_true_one_hot)[2:]], axis=0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since some of the images in a batch may have fewer than `n_inst_max` instances, we need to avoid zero-divison error.\n",
    "- To do so we rewrite the loss function\n",
    "- First note that \n",
    "\n",
    "    $$\\left\\lVert u - \\frac{v}{q} \\right\\rVert \n",
    "    = \\sqrt{\\sum_i\\left(u_i -  \\frac{v_i}{q}\\right)^2}\n",
    "    = \\sqrt{\\sum_i \\frac{1}{q^2}\\left(q\\cdot u_i -  v_i\\right)^2}\n",
    "     = \\frac{1}{q}\\sqrt{\\sum_i\\left(q\\cdot u_i -  v_i\\right)^2}\n",
    "     = \\frac{1}{q}\\left\\lVert q\\cdot u - v \\right\\rVert $$\n",
    "     \n",
    "     \n",
    "- The loss function becomes\n",
    "\n",
    "    $$\\mathcal{L}(\\Psi|\\mathbf{x}, \\mathcal{S}) = \n",
    "    \\sum_{S \\in \\mathcal{S}} \\frac{1}{\\lvert S \\rvert^2}\n",
    "    \\sum_{u \\in S}\\left\\lVert{\\lvert S \\rvert}\\cdot\\Psi_u(\\mathbf{x}) - \\sum_{u \\in S}\\Psi_u(\\mathbf{x})\\right\\rVert$$\n",
    "    \n",
    "    \n",
    "    \n",
    "- In the code below we first find the sum of the Euclidean distance for each the `batch_size` $\\times$ `n_inst_max` rows in `y_pred_dense`.\n",
    "\n",
    "\n",
    "- Then we select only those from the rows that correspond to an instance before dividing by `n_inst_pixels` thus avoiding division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #find number of pixels in each instance\n",
    "    #(batch_size*n_inst_max) x height x width -> (batch_size*n_inst_max)\n",
    "    n_inst_pixels = tf.reduce_sum(y_true_one_hot, axis=[1, 2])\n",
    "    \n",
    "    #(batch_size*n_inst_max) x height x width x channels -> (batch_size*n_inst_max) x channels\n",
    "    embeds_sum = tf.reduce_sum(y_pred_dense, axis=[1,2], keep_dims=True)\n",
    "    #(batch_size*n_inst_max) x height x width x channels -> (batch_size*n_inst_max) x height x width\n",
    "    dist = tf.norm(y_pred_dense*n_inst_pixels - embeds_sum, axis=-1)\n",
    "    \n",
    "    #keep only the distances for pixels that belong to the instance\n",
    "    dist_masked = dist*y_true_one_hot\n",
    "    \n",
    "    #sum the losses for each instance\n",
    "    #(batch_size*n_inst_max) x height x width -> (batch_size*n_inst_max)\n",
    "    dist_sum = tf.reduce_sum(dist_masked, axis=[1,2])\n",
    "    has_inst_mask = tf.greater(n_inst_pixels, 0)\n",
    "    \n",
    "    #select only the elements of dist that correspond to an instance\n",
    "    losses = (tf.boolean_mask(dist_sum, has_inst_mask)/\n",
    "                tf.boolean_mask(n_inst_pixels, has_inst_mask)**2)\n",
    "    \n",
    "    loss = tf.reduce_sum(losses)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU Score\n",
    "\n",
    "Implements the evaluation metric described at https://www.kaggle.com/c/airbus-ship-detection#evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(y_true, y_pred):\n",
    "    thresholds = tf.constant([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "    beta = 2\n",
    "    \n",
    "    n_inst_max = tf.max(y_true) \n",
    "    n_pred_max = tf.max(y_pred) \n",
    "    \n",
    "    #B x H X W x I x 1 \n",
    "    y_true_one_hot = tf.one_hot(y_true, depth=n_inst_max, axis=-1)[...,np.newaxis]\n",
    "    #B x H x W x 1 x P\n",
    "    y_pred_one_hot = tf.one_hot(y_pred, depth=n_pred_max, axis=-1)[...,np.newaxis,:]\n",
    "    \n",
    "    #B x I x P\n",
    "    intersection = tf.reduce_sum(y_true*y_pred, axis=[1,2])\n",
    "    #B x I x P\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2]) + tf.reduce_sum(y_pred, axis=[1,2]) - intersection\n",
    "    \n",
    "    #B x I x P\n",
    "    iou_masked = intersection/tf.where(tf.greater(union, 0), union, tf.ones_like(union))\n",
    "    \n",
    "    #B x I x P x T\n",
    "    match = tf.greater(iou_masked[...,tf.newaxis], thresholds)\n",
    "    \n",
    "    #B x I x T\n",
    "    inst_match_at_thresh = tf.to_float32(tf.reduce_any(match, axis=[-2]))\n",
    "    \n",
    "    #B x P x T\n",
    "    pred_match_at_thresh = tf.to_float32(tf.reduce_any(match, axis=[-3]))\n",
    "    \n",
    "    #T\n",
    "    tp_at_thresh = tf.reduce_sum(inst_match_at_thresh, axis=[0, 1])\n",
    "    fn_at_thresh = tf.reduce_sum(1 - inst_match_at_thresh, axis=[0, 1])\n",
    "    fp_at_thresh = tf.reduce_sum(1 - pred_match_at_thresh, axis=[0, 1])\n",
    "    \n",
    "    f2_numerator = (1 + beta**2)*tp_at_thresh\n",
    "    f2_score = f2_numerator/(f2_numerator + (beta**2)*fn_at_thresh + fp_at_thresh)\n",
    "    mean_f2_score = tf.reduce_mean(f2_score, axis=0)\n",
    "    \n",
    "    return mean_f2_score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
