{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford CS168 mini-project #1, Part 2\n",
    "\n",
    "These are my solutions to Part 2 of [mini-project #1](https://web.stanford.edu/class/cs168/p1.pdf) of the Spring 2018 rendition of [Stanford's CS168:  The Modern Algorithmic Toolbox](https://web.stanford.edu/class/cs168). This assignment covers some applications of hashing. Be warned that I am a learner myself so answers are not guaranteed to be error-free by any means as and I am not a Stanford student so do not have access to the solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections (a),(d) - Implementation of CMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountMinSketch(object):\n",
    "    \"\"\"\n",
    "    Implementation of CountMinSketch datastructure as specified in Part 2(a) of assignment \n",
    "    and including conservative update mode as specified in Part 2(f)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trial, n_tables, n_counters, mode='all'):\n",
    "        \"\"\"\n",
    "        Initialises a CountMinSketch object with specified paramters\n",
    "        \n",
    "        Params:\n",
    "            trial: i in assignment\n",
    "            n_tables: l in notes (parameter of CMS)\n",
    "            n_counters: b in notes (paramter of CMS)\n",
    "            mode: for updating the counters\n",
    "        \"\"\"\n",
    "        self.trial = trial\n",
    "        self.n_counters = n_counters\n",
    "        self.n_tables = n_tables\n",
    "        self.table_inds = np.arange(self.n_tables)[:,np.newaxis]\n",
    "        self.data = np.zeros((n_tables, n_counters)).astype('int')\n",
    "        self.mode = mode\n",
    "        \n",
    "    def _hash_fn(self, x, table):\n",
    "        i = self.trial\n",
    "        j = table\n",
    "        return np.array(hashlib.md5((str(x)+str(i-1)).encode('utf-8')).digest()[j-1]).astype('int')\n",
    "        \n",
    "    def inc(self, x):\n",
    "        \"\"\"\n",
    "        Increments count for a subset of counters identified by the hash of x in the present trial.\n",
    "        The subset is all the counters in the default 'all' mode or only those with the minimum\n",
    "        count across all counters if the mode is 'conservative'.\n",
    "        \n",
    "        Params:\n",
    "            x: element whose count will be incremented \n",
    "        \"\"\"\n",
    "        if self.mode == 'conservative':\n",
    "            assert np.size(x) == 1\n",
    "            inds = self._get_min_inds(x)\n",
    "        else:\n",
    "            inds = (self.table_inds, self.get_hashes(x))\n",
    "            \n",
    "        self.data[inds] += 1\n",
    "        \n",
    "    def _get_min_inds(self, x):\n",
    "        \"\"\"\n",
    "        Obtains indices for minimum counters\n",
    "        \n",
    "        Params:\n",
    "            x: element for which the counters with lowest count will be identified\n",
    "        \n",
    "        Returns:\n",
    "            The tables and indexing hashes for the subset of counters \n",
    "            with minimum count\n",
    "        \"\"\"\n",
    "        min_counts, counts, hashes = self.count(x, True)\n",
    "        min_rows = counts==min_counts\n",
    "        return self.table_inds[min_rows], hashes[min_rows]\n",
    "        \n",
    "    def count(self, x, _return_counts_and_hashes=False):\n",
    "        \"\"\"\n",
    "        Obtains count for x \n",
    "        \n",
    "        Prarams\n",
    "            x: element for which the minimum count will be returned\n",
    "            _return_counts_and_hashes: whether to return counts and hashes used to find \n",
    "                the minimum count, used internally by _get_min_inds\n",
    "            \n",
    "        Returns:\n",
    "            The minimum count across all tables for x, which is guaranteed never to\n",
    "            be an underestimate of the true frequency of x  \n",
    "        \"\"\"\n",
    "        hashes = self.get_hashes(x)\n",
    "        counts = self.data[self.table_inds, hashes]\n",
    "        min_counts = np.min(counts, axis=0)\n",
    "        if _return_counts_and_hashes:\n",
    "            return min_counts, counts, hashes\n",
    "        return min_counts\n",
    "    \n",
    "    def get_hashes(self, vec):\n",
    "        \"\"\"\n",
    "        Applies _hash_fn to each element in each table \n",
    "        \n",
    "        Params\n",
    "            vec: vector of elements to hash\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "            n_tables x len(vec) matrix of hashes\n",
    "        \"\"\"\n",
    "        vec = np.reshape(vec, [-1])\n",
    "        n_elems = len(vec)\n",
    "        tables = self.table_inds.ravel()\n",
    "        \n",
    "        result = np.zeros((self.n_tables, n_elems)).astype('int')\n",
    "        \n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            for j, elem in enumerate(vec):\n",
    "                result[i][j] = self._hash_fn(elem, table)\n",
    "        return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section (b) - Datastreams\n",
    "\n",
    "Functions for data generation that will be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(x):\n",
    "    \"\"\"\n",
    "    Functionalises the frequencies for the datastreams\n",
    "    \n",
    "    Params:\n",
    "        x: element or vector whose frequency will be returned, must be in [1,9050]\n",
    "    \n",
    "    Returns:\n",
    "        frequency as specified in Part 2(a)\n",
    "    Raises:\n",
    "        ValueError if x is not in specified range\n",
    "    \"\"\"\n",
    "    \n",
    "    if not np.all(np.logical_and(x>=1, x<=9050)):\n",
    "        raise ValueError('Values must be between 1 and 9050 inclusive')\n",
    "    i = (x-1)//1000 + 1\n",
    "    return np.where(i<=9, i, (x-9000)**2)\n",
    "\n",
    "def data_stream(order):\n",
    "    \"\"\"\n",
    "    Generates datastream with elements in [1,9050] with\n",
    "    frequencies given by freq in either ascending or descending\n",
    "    order of value (and in fact frequency) or in random order.\n",
    "    \n",
    "    Params:\n",
    "        order: how the elements are to be ordered by value, one\n",
    "            of 'forward', 'backward', or 'random'\n",
    "    Returns:\n",
    "        Array of elements in [1, 9050] in specified order and frequencies\n",
    "        given by freq\n",
    "    Raises:\n",
    "        ValueError if order is not one of 'forward', 'backward', or 'random'\n",
    "    \"\"\"\n",
    "    if order not in {'forward', 'backward', 'random'}:\n",
    "        raise ValueError(\"x must be one of 'forward', 'backward', or 'random'\")\n",
    "    if order == 'backward':\n",
    "        x = np.arange(9050,0,-1)\n",
    "    else:\n",
    "        x = np.arange(1,9051)\n",
    "    f = freq(x)\n",
    "    stream = np.concatenate([[xi]*fi for xi, fi in zip(x, f)])\n",
    "    if order == 'random':\n",
    "        stream = np.random.permutation(stream)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the number of heavy hitters first sum the frequencies for each element. There is no need to invoke `freq` for this purpose. For the first 9000 elements, the count increases by one for every 1000 elements hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_first9k = 1000*(np.arange(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last 50 elements, the count is $(i - 9000)^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_last50 = np.arange(1,51)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the total and heavy hitter threshold frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87925, 879.25)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = counts_first9k.sum() + counts_last50.sum()\n",
    "freq_hh = total*0.01\n",
    "total, freq_hh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the frequency of values $\\leq 9000$ is upper bounded by $9$, heavy hitters must be in the set of values $\\gt 9000$. Since their frequency is $i^2$, heavy hitters are \n",
    "\n",
    "$$\\{9000 + i: i \\geq \\sqrt{879.25}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.652150006365474\n",
      "21\n",
      "[9030 9031 9032 9033 9034 9035 9036 9037 9038 9039 9040 9041 9042 9043\n",
      " 9044 9045 9046 9047 9048 9049 9050]\n"
     ]
    }
   ],
   "source": [
    "thresh = np.sqrt(freq_hh)\n",
    "print(thresh)\n",
    "heavy_hitters = 9000 + np.arange(np.ceil(thresh).astype(np.int64), 51)\n",
    "print(len(heavy_hitters))\n",
    "print(heavy_hitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections (c), (f) - Trials with CMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(n_trials, n_tables, n_counters, mode='all'):\n",
    "    \"\"\"\n",
    "    Generates datastreams in forward, backward and random orders \n",
    "    and updates and analyses a CountMinSketch with given mode for each. \n",
    "    \n",
    "    n_trials: number of trials per datastream order and mode\n",
    "    n_tables: parameter l for CMS\n",
    "    n_counters: parameter b for CMS\n",
    "    mode: update mode for CMS\n",
    "    \n",
    "    Returns a dictionary of results for each datastream order \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    n_elems = None\n",
    "    for order in ['forward', 'backward', 'random']:\n",
    "        print(order.capitalize())\n",
    "        if order != 'random':\n",
    "            stream = data_stream(order)\n",
    "        results[order] = {'count_9050':[], 'n_heavy_hitters':[]}\n",
    "        for trial in range(1, n_trials+1):\n",
    "            if order == 'random':\n",
    "                stream = data_stream(order)\n",
    "            print('Trial {}/{}'.format(trial, n_trials))\n",
    "            CMS = CountMinSketch(trial, n_tables, n_counters, mode)\n",
    "            if n_elems is None:\n",
    "                n_elems = len(stream)\n",
    "            for i, elem in enumerate(stream):\n",
    "                if not i%10:\n",
    "                    sys.stdout.write('\\r{}/{}'.format(i, n_elems))\n",
    "                CMS.inc(elem)\n",
    "            results[order]['count_9050'].append(CMS.count(9050)[0])\n",
    "            counts = CMS.count(np.arange(1, 9051))\n",
    "            n_heavy_hitters = np.sum(counts >= (len(stream)*0.01))\n",
    "            results[order]['n_heavy_hitters'].append(n_heavy_hitters)\n",
    "            print()\n",
    "            print(results[order])\n",
    "    \n",
    "    return results     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "Forward\n",
      "Trial 1/10\n",
      "87920/87925\n",
      "{'count_9050': [2625], 'n_heavy_hitters': [24]}\n",
      "Trial 2/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633], 'n_heavy_hitters': [24, 25]}\n",
      "Trial 3/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654], 'n_heavy_hitters': [24, 25, 23]}\n",
      "Trial 4/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654], 'n_heavy_hitters': [24, 25, 23, 25]}\n",
      "Trial 5/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623], 'n_heavy_hitters': [24, 25, 23, 25, 23]}\n",
      "Trial 6/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25]}\n",
      "Trial 7/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23]}\n",
      "Trial 8/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23]}\n",
      "Trial 9/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653, 2641], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23, 26]}\n",
      "Trial 10/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653, 2641, 2682], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23, 26, 24]}\n",
      "Backward\n",
      "Trial 1/10\n",
      "87920/87925\n",
      "{'count_9050': [2625], 'n_heavy_hitters': [24]}\n",
      "Trial 2/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633], 'n_heavy_hitters': [24, 25]}\n",
      "Trial 3/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654], 'n_heavy_hitters': [24, 25, 23]}\n",
      "Trial 4/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654], 'n_heavy_hitters': [24, 25, 23, 25]}\n",
      "Trial 5/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623], 'n_heavy_hitters': [24, 25, 23, 25, 23]}\n",
      "Trial 6/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25]}\n",
      "Trial 7/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23]}\n",
      "Trial 8/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23]}\n",
      "Trial 9/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653, 2641], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23, 26]}\n",
      "Trial 10/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653, 2641, 2682], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23, 26, 24]}\n",
      "Random\n",
      "Trial 1/10\n",
      "87920/87925\n",
      "{'count_9050': [2625], 'n_heavy_hitters': [24]}\n",
      "Trial 2/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633], 'n_heavy_hitters': [24, 25]}\n",
      "Trial 3/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654], 'n_heavy_hitters': [24, 25, 23]}\n",
      "Trial 4/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654], 'n_heavy_hitters': [24, 25, 23, 25]}\n",
      "Trial 5/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623], 'n_heavy_hitters': [24, 25, 23, 25, 23]}\n",
      "Trial 6/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25]}\n",
      "Trial 7/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23]}\n",
      "Trial 8/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23]}\n",
      "Trial 9/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653, 2641], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23, 26]}\n",
      "Trial 10/10\n",
      "87920/87925\n",
      "{'count_9050': [2625, 2633, 2654, 2654, 2623, 2655, 2645, 2653, 2641, 2682], 'n_heavy_hitters': [24, 25, 23, 25, 23, 25, 23, 23, 26, 24]}\n",
      "Conservative\n",
      "Forward\n",
      "Trial 1/10\n",
      "87920/87925\n",
      "{'count_9050': [2568], 'n_heavy_hitters': [22]}\n",
      "Trial 2/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580], 'n_heavy_hitters': [22, 22]}\n",
      "Trial 3/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583], 'n_heavy_hitters': [22, 22, 22]}\n",
      "Trial 4/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581], 'n_heavy_hitters': [22, 22, 22, 23]}\n",
      "Trial 5/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581, 2567], 'n_heavy_hitters': [22, 22, 22, 23, 22]}\n",
      "Trial 6/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581, 2567, 2578], 'n_heavy_hitters': [22, 22, 22, 23, 22, 23]}\n",
      "Trial 7/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581, 2567, 2578, 2570], 'n_heavy_hitters': [22, 22, 22, 23, 22, 23, 22]}\n",
      "Trial 8/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581, 2567, 2578, 2570, 2581], 'n_heavy_hitters': [22, 22, 22, 23, 22, 23, 22, 22]}\n",
      "Trial 9/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581, 2567, 2578, 2570, 2581, 2576], 'n_heavy_hitters': [22, 22, 22, 23, 22, 23, 22, 22, 24]}\n",
      "Trial 10/10\n",
      "87920/87925\n",
      "{'count_9050': [2568, 2580, 2583, 2581, 2567, 2578, 2570, 2581, 2576, 2581], 'n_heavy_hitters': [22, 22, 22, 23, 22, 23, 22, 22, 24, 22]}\n",
      "Backward\n",
      "Trial 1/10\n",
      "87920/87925\n",
      "{'count_9050': [2500], 'n_heavy_hitters': [21]}\n",
      "Trial 2/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500], 'n_heavy_hitters': [21, 21]}\n",
      "Trial 3/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21]}\n",
      "Trial 4/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22]}\n",
      "Trial 5/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21]}\n",
      "Trial 6/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22]}\n",
      "Trial 7/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21]}\n",
      "Trial 8/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21, 21]}\n",
      "Trial 9/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21, 21, 23]}\n",
      "Trial 10/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21, 21, 23, 21]}\n",
      "Random\n",
      "Trial 1/10\n",
      "87920/87925\n",
      "{'count_9050': [2500], 'n_heavy_hitters': [21]}\n",
      "Trial 2/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500], 'n_heavy_hitters': [21, 21]}\n",
      "Trial 3/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21]}\n",
      "Trial 4/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22]}\n",
      "Trial 5/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21]}\n",
      "Trial 6/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22]}\n",
      "Trial 7/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21]}\n",
      "Trial 8/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21, 21]}\n",
      "Trial 9/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21, 21, 23]}\n",
      "Trial 10/10\n",
      "87920/87925\n",
      "{'count_9050': [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500], 'n_heavy_hitters': [21, 21, 21, 22, 21, 22, 21, 21, 23, 21]}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for mode in ['all', 'conservative']:\n",
    "    print(mode.capitalize())\n",
    "    results[mode] = run_trial(10, 4, 256, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Mode: all\n",
      "====================\n",
      "Order: forward\n",
      "--------------------\n",
      "true count_9050: 2500 | CMS count_9050: 2646.5\n",
      "true heavy hitters: 21 | CMS heavy hitters: 24.1\n",
      "\n",
      "Order: backward\n",
      "--------------------\n",
      "true count_9050: 2500 | CMS count_9050: 2646.5\n",
      "true heavy hitters: 21 | CMS heavy hitters: 24.1\n",
      "\n",
      "Order: random\n",
      "--------------------\n",
      "true count_9050: 2500 | CMS count_9050: 2646.5\n",
      "true heavy hitters: 21 | CMS heavy hitters: 24.1\n",
      "\n",
      "\n",
      "====================\n",
      "Mode: conservative\n",
      "====================\n",
      "Order: forward\n",
      "--------------------\n",
      "true count_9050: 2500 | CMS count_9050: 2576.5\n",
      "true heavy hitters: 21 | CMS heavy hitters: 22.4\n",
      "\n",
      "Order: backward\n",
      "--------------------\n",
      "true count_9050: 2500 | CMS count_9050: 2500.0\n",
      "true heavy hitters: 21 | CMS heavy hitters: 21.4\n",
      "\n",
      "Order: random\n",
      "--------------------\n",
      "true count_9050: 2500 | CMS count_9050: 2500.0\n",
      "true heavy hitters: 21 | CMS heavy hitters: 21.4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reps = 50\n",
    "for k,v in results.items():\n",
    "    print('='*reps)\n",
    "    print('Mode:', k)\n",
    "    print('='*reps)\n",
    "    for order in ['forward', 'backward', 'random']:\n",
    "        print('Order:', order)\n",
    "        print('-'*reps)\n",
    "        print('true count_9050:', freq(9050), '| CMS count_9050:', np.mean(v[order]['count_9050']))\n",
    "        print('true heavy hitters:', len(heavy_hitters), '| CMS heavy hitters:',np.mean(v[order]['n_heavy_hitters']))\n",
    "        print()\n",
    "    print('*'*reps)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the default update mode, order does not matter because each update is independent of the previous and whatever the order of elements all tables get updated so each time the minimum count is the same. But with conservative updates, as the results indicate, order matters since whether or not a counter gets updated depends on the history of updates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section(e) why even with conservative updates CMS never underestimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Let $n_x = \\{0, 1, 2, \\ldots, f_x\\}$ denote the number of times element $x$ has been seen in the stream so far. This is equivalently the number of times the CMS function `inc` has been called for $x$. We will prove that the CMS never underestimates by showing that after $n_x$ calls of `inc` of $x$, $\\min_i CMS[i][h_i(x)] \\ge n_x$ or equivalently $\\forall_i CMS[i][h_i(x)] \\ge n_x$. We rely on the fact that the counts of $x$ cannot decrease between occurences of $x$ since counters can never be decremented.\n",
    "\n",
    "**Base case, no updates, $n_x = 0$**\n",
    "\n",
    "Before the element is seen, $\\min_i CMS[i][h_i(x)] \\ge 0 \\ge n_x$. (If there have been previous collisions with $y\\neq x$ involving the hash function corresponding to the lowest counter for $y$, counters may have been updated already).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base case, first update, $n_x = 1$**\n",
    "\n",
    "Before calling `inc`, $\\min_i CMS[i][h_i(x)] \\ge 0$. Therefore the subset of counters which are strictly greater than the minimum must have a count of at least 1 i.e. \n",
    "\n",
    "$$\\forall n \\notin \\{m: CMS[m][h_m(x)] = \\min CMS[i][h_i(x)]\\},\\text{ } CMS[n][h_n(x)] \\ge 1$$\n",
    "\n",
    "After calling `inc`, the subset of counters with minimum count increases by 1 so that now all counters have a count of at least 1, $CMS[i][h_i(x)] \\ge 1 = n_x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inductive step, $n_x = k$**\n",
    "\n",
    "Assume that before calling `inc`, $\\min_i CMS[i][h_i(x)] \\ge k-1$. After calling `inc` we should have that it equals $k$. Similar to the reasoning for the base case of $n_x = 1$ note the following for the non-minimum counters:\n",
    "\n",
    "$$\\forall n \\notin \\{m: CMS[m][h_m(x)] = \\min CMS[i][h_i(x)]\\},\\text{ } CMS[n][h_n(x)] \\ge k$$\n",
    "\n",
    "Again similar to before, after calling `inc`, $\\forall_i CMS[i][h_i(x)] \\ge k = n_x$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
